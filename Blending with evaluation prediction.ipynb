{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.multioutput import MultiOutputClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=[[1,2,5,3],[5,2,4,2],[2,3,5,3],[4,1,3,2],[1,3,4,2]]\n",
    "y=[[2,3],[2],[0,1,3],[1,2,3],[0,1,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_trans=MultiLabelBinarizer().fit_transform(y)\n",
    "y_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(X),type(y_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(X),y_trans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fit_forest=RandomForestClassifier(n_estimators=100,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model1=OneVsRestClassifier(fit_forest).fit(X,y_trans)\n",
    "print(model1.predict([[2,3,2,4]]))\n",
    "print(model1.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MultiOutputRegressor(fit_forest).fit(X,y_trans).predict([[2,3,2,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MultiOutputClassifier(linear_model.LogisticRegression(C=1e5)).fit(X, y_trans).predict([[2,3,2,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MultiOutputClassifier(fit_forest).fit(X, y_trans).predict([[2,3,2,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_df=pd.DataFrame(X)\n",
    "y_df=pd.DataFrame(y_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MultiOutputClassifier(fit_forest).fit(X_df, y_df).predict([[2,3,2,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yhat=model1.predict(X_df)\n",
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phat=model1.predict_proba(X_df)\n",
    "phat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hat={}\n",
    "for i in range(len(phat)):\n",
    "    b={j:phat[i][j] for j in range(len(phat[i]))}\n",
    "    b_sort=sorted(b.items(),key=lambda x:x[1],reverse=True)\n",
    "    a=b_sort[0:2]\n",
    "    c=''\n",
    "    for j in a:\n",
    "        temp=\" \".join(map(str,j))\n",
    "        c=c+temp+' '\n",
    "    hat['id'+str(i)]=c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_stacking=pd.DataFrame(pd.Series(hat),index=hat.keys(),columns=['LabelConfidencePair'])\n",
    "final_stacking.index.name='VideoId'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "video_lvl_record = \"/Users/shujiaohuang_Mac/Downloads/test-1.tfrecord\"\n",
    "vid_ids = []\n",
    "labels = []\n",
    "mean_rgb = []\n",
    "mean_audio = []\n",
    "\n",
    "for example in tf.python_io.tf_record_iterator(video_lvl_record):\n",
    "    tf_example = tf.train.Example.FromString(example)\n",
    "    vid_ids.append(tf_example.features.feature['video_id'].bytes_list.value[0].decode(encoding='UTF-8'))\n",
    "    labels.append(tf_example.features.feature['labels'].int64_list.value)\n",
    "    mean_rgb.append(tf_example.features.feature['mean_rgb'].float_list.value)\n",
    "    mean_audio.append(tf_example.features.feature['mean_audio'].float_list.value)\n",
    "tf_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd \n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn import linear_model\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write prediction to matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stacking_feature(file):\n",
    "    from sklearn.feature_extraction import DictVectorizer\n",
    "    lines=open(file).readlines()\n",
    "    result=[]\n",
    "    file_id=[]\n",
    "    for e,line in enumerate(lines):\n",
    "        if e>0:\n",
    "            row=line.strip().split(\",\")\n",
    "            string_list=row[1].split(\" \")\n",
    "            float_list=[float(string_list[x]) if x%2==1 else string_list[x] for x in range(0,len(string_list))]\n",
    "            newlist=[float_list[x:x+2] for x in range(0,len(float_list),2)]\n",
    "            score_dict={}\n",
    "            for x in range(0,len(newlist)):\n",
    "                score_dict[newlist[x][0]]=(newlist[x][1])\n",
    "            result.append(score_dict)\n",
    "            file_id.append(row[0])\n",
    "    feature=DictVectorizer(sparse=False).fit_transform(result)\n",
    "    return file_id,feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _int64list_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _floats_feature(value):\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=value)) \n",
    "\n",
    "\n",
    "class NumpyToTFHelper(object):\n",
    "    def __init__(self,filenames):\n",
    "        self.filenames = filenames\n",
    "        self.current_file = -1\n",
    "        self.current_index = 0 \n",
    "        self.current_array = None\n",
    "    def get_next(self):\n",
    "        if self.current_file<len(self.filenames)-1:\n",
    "            self.current_file += 1\n",
    "            self.current_array = self.filenames[self.current_file]\n",
    "        else:\n",
    "            return None\n",
    "        self.current_index+=1\n",
    "        cur = self.filenames[self.current_index -1] \n",
    "        return np.matrix(cur).A1\n",
    "\n",
    "\n",
    "#class NumpyToTFHelper(object):\n",
    "#    def __init__(self,filenames):\n",
    "#        self.filenames = filenames\n",
    "#        self.current_file = -1\n",
    "#        self.current_index = 0 \n",
    "#        self.current_array = None\n",
    "#    def get_next(self):\n",
    "#        if self.current_file == -1: \n",
    "#            self.current_file += 1\n",
    "#            self.current_array = np.load(self.filenames[self.current_file])['arr_0']\n",
    "#        elif self.current_index == self.current_array.shape[0]-1:\n",
    "#            if self.current_file == len(self.filenames) - 1:\n",
    "#                return None\n",
    "#            self.current_file += 1\n",
    "#            self.current_array = np.load(self.filenames[self.current_file])['arr_0']\n",
    "#            self.current_index = 0 \n",
    "#        self.current_index += 1 \n",
    "#        # return single 16000 length record\n",
    "#        cur = self.current_array[self.current_index -1] \n",
    "#        #print(cur.shape)\n",
    "#        #print(type(cur))\n",
    "#        return np.matrix(cur).A1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_y = pd.read_csv(\"/Users/shujiaohuang_Mac/Downloads/validate_labels.csv\",header=None).as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1401828, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['--h7o0bAOpk', '0 2 581 111 55 317'],\n",
       "       ['--O5HgNtvSc', '208 1 3073 1294 1073'],\n",
       "       ['--q4Vg_nqEw', '0 656 2 19 2677'],\n",
       "       ..., \n",
       "       ['zz9LRC0P8Os', '0 25 2 23'],\n",
       "       ['zz4DceTfj-c', '1946 15'],\n",
       "       ['zzvd6yEiOmk', '0 1 2 388 50']], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#val_y_aslist=[]\n",
    "#for i in val_y[1]:\n",
    "#    val_y_aslist.append(i.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(type(val_y_aslist))\n",
    "#print(len(val_y_aslist))\n",
    "#print(val_y_aslist[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#val_y_bin=MultiLabelBinarizer().fit_transform(val_y_aslist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(type(val_y_bin))\n",
    "#print(val_y_bin.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#val_y_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#val_y_bin[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#val_y_bin[0:3][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#np.savez('val_y_bin.npz',val_y_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#y_train=pd.DataFrame(val_y_bin)\n",
    "#y_train=val_y_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(type(y_train))\n",
    "#print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#y_train[0:10],y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#y_train[0:1000].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# merge tfrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read test.tfrecord\n",
    "moe_val_1='/Users/shujiaohuang_Mac/Downloads/moe_val_5w_1.tfrecord'\n",
    "for example in tf.python_io.tf_record_iterator(video_lvl_record):\n",
    "    tf_example = tf.train.Example.FromString(example)\n",
    "    break\n",
    "tf_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfile=\\'/Users/shujiaohuang_Mac/Downloads/moe_2feature_eval_predictions.csv\\'\\nfrom sklearn.feature_extraction import DictVectorizer\\nlines=open(file).readlines()\\nresult=[]\\nfile_id=[]\\nfor e,line in enumerate(lines):\\n    if e>0:\\n        if e<11:\\n            row=line.strip().split(\",\")\\n            string_list=row[1].split(\" \")\\n            float_list=[float(string_list[x]) if x%2==1 else string_list[x] for x in range(0,len(string_list))]\\n            newlist=[float_list[x:x+2] for x in range(0,len(float_list),2)]\\n            score_dict={}\\n            for x in range(0,len(newlist)):\\n                score_dict[newlist[x][0]]=(newlist[x][1])\\n            result.append(score_dict)\\n            file_id.append(row[0])\\n\\nmoe_2feature_eval_stacking_new_feature=DictVectorizer(sparse=False).fit_transform(result)\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "file='/Users/shujiaohuang_Mac/Downloads/moe_2feature_eval_predictions.csv'\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "lines=open(file).readlines()\n",
    "result=[]\n",
    "file_id=[]\n",
    "for e,line in enumerate(lines):\n",
    "    if e>0:\n",
    "        if e<11:\n",
    "            row=line.strip().split(\",\")\n",
    "            string_list=row[1].split(\" \")\n",
    "            float_list=[float(string_list[x]) if x%2==1 else string_list[x] for x in range(0,len(string_list))]\n",
    "            newlist=[float_list[x:x+2] for x in range(0,len(float_list),2)]\n",
    "            score_dict={}\n",
    "            for x in range(0,len(newlist)):\n",
    "                score_dict[newlist[x][0]]=(newlist[x][1])\n",
    "            result.append(score_dict)\n",
    "            file_id.append(row[0])\n",
    "\n",
    "moe_2feature_eval_stacking_new_feature=DictVectorizer(sparse=False).fit_transform(result)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "moe_2feature_eval_stacking_new_feature_withid=stacking_feature('/Users/shujiaohuang_Mac/Downloads/moe_2feature_eval_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(moe_2feature_eval_stacking_new_feature_withid),type(logistic_2feature_eval_stacking_new_feature_withid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.682859,  0.044098,  0.      , ...,  0.      ,  0.      ,  0.      ],\n",
       "       [ 0.      ,  0.978585,  0.      , ...,  0.      ,  0.      ,  0.      ],\n",
       "       [ 0.999238,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ],\n",
       "       ..., \n",
       "       [ 0.999989,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ],\n",
       "       [ 0.01214 ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ],\n",
       "       [ 0.654479,  0.982899,  0.      , ...,  0.      ,  0.      ,  0.      ]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moe_2feature_eval_stacking_new_feature=moe_2feature_eval_stacking_new_feature_withid[1]\n",
    "moe_2feature_eval_stacking_new_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1401828, 4716)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moe_2feature_eval_stacking_new_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bytes_list {\n",
      "  value: \"--h7o0bAOpk\"\n",
      "}\n",
      "\n",
      "bytes_list {\n",
      "  value: \"--O5HgNtvSc\"\n",
      "}\n",
      "\n",
      "bytes_list {\n",
      "  value: \"--q4Vg_nqEw\"\n",
      "}\n",
      "\n",
      "bytes_list {\n",
      "  value: \"--wpV2HK8zQ\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# try\n",
    "iter=1\n",
    "num=4\n",
    "X_top=moe_2feature_eval_stacking_new_feature[int(iter-1)*num:int(iter)*num]\n",
    "y_top=val_y[int(iter-1)*num:int(iter)*num]\n",
    "N_X = NumpyToTFHelper(X_top) \n",
    "n_X = N_X.get_next()\n",
    "N_y = NumpyToTFHelper(y_top)\n",
    "n_y = N_y.get_next()\n",
    "while n_X is not None:\n",
    "    example = tf.train.Example(\n",
    "        features=tf.train.Features(\n",
    "            feature={\n",
    "                'video_id':_bytes_feature(bytes(n_y[0],'utf-8')),\n",
    "                'labels':_int64list_feature([int(i) for i in n_y[1].split(' ')]),\n",
    "                'New_feature':_floats_feature([float(i) for i in n_X])\n",
    "            }\n",
    "        )\n",
    "    ) \n",
    "    print(example.features.feature['video_id'])\n",
    "    n_X=N_X.get_next()\n",
    "    n_y = N_y.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['--h7o0bAOpk', '0 2 581 111 55 317'],\n",
       "       ['--O5HgNtvSc', '208 1 3073 1294 1073'],\n",
       "       ['--q4Vg_nqEw', '0 656 2 19 2677'],\n",
       "       ['--wpV2HK8zQ', '676 28']], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "[1]\n",
      "False\n",
      "(1401828, 4716)\n"
     ]
    }
   ],
   "source": [
    "num=1401828\n",
    "print(moe_2feature_eval_stacking_new_feature.shape[0]/num)\n",
    "print([i for i in range(1,2)])\n",
    "iter=1\n",
    "print(iter<moe_2feature_eval_stacking_new_feature.shape[0]/num)\n",
    "print(moe_2feature_eval_stacking_new_feature[int(iter-1)*num::].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.01828"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1401828/100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num=100000\n",
    "for iter in range(9,16):\n",
    "    if iter<moe_2feature_eval_stacking_new_feature.shape[0]/num:\n",
    "        X_top=moe_2feature_eval_stacking_new_feature[int(iter-1)*num:int(iter)*num]\n",
    "        y_top=val_y[int(iter-1)*num:int(iter)*num]\n",
    "    else:\n",
    "        X_top=moe_2feature_eval_stacking_new_feature[int(iter-1)*num::]\n",
    "        y_top=val_y[int(iter-1)*num::]\n",
    "    filename='moe_val_10w_'+str(iter)+'.tfrecord'\n",
    "    writer = tf.python_io.TFRecordWriter(filename)\n",
    "    N_X = NumpyToTFHelper(X_top) \n",
    "    n_X = N_X.get_next()\n",
    "    N_y = NumpyToTFHelper(y_top)\n",
    "    n_y = N_y.get_next()\n",
    "    while n_X is not None:\n",
    "        example = tf.train.Example(\n",
    "            features=tf.train.Features(\n",
    "                feature={\n",
    "                    'video_id':_bytes_feature(bytes(n_y[0],'utf-8')),\n",
    "                    'labels':_int64list_feature([int(i) for i in n_y[1].split(' ')]),\n",
    "                    'New_feature':_floats_feature([float(i) for i in n_X])\n",
    "                }\n",
    "            )\n",
    "        ) \n",
    "        writer.write(example.SerializeToString())\n",
    "        n_X=N_X.get_next()\n",
    "        n_y = N_y.get_next()\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logistic_2feature_eval_stacking_new_feature_withid=stacking_feature('/Users/shujiaohuang_Mac/Downloads/logistic_val_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logistic_2feature_eval_stacking_new_feature=logistic_2feature_eval_stacking_new_feature_withid[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.907931,  0.02949 ,  0.      , ...,  0.      ,  0.      ,  0.      ],\n",
       "       [ 0.      ,  0.976476,  0.      , ...,  0.      ,  0.      ,  0.      ],\n",
       "       [ 0.999979,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ],\n",
       "       ..., \n",
       "       [ 0.999975,  0.016853,  0.      , ...,  0.      ,  0.      ,  0.      ],\n",
       "       [ 0.048551,  0.004482,  0.      , ...,  0.      ,  0.      ,  0.      ],\n",
       "       [ 0.465478,  0.954355,  0.      , ...,  0.      ,  0.      ,  0.      ]])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_2feature_eval_stacking_new_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "# Both moe and logisitc val tfrecord\n",
    "for iteration in range(3,16):\n",
    "    print(iteration)\n",
    "    file_iter='10w_'+str(iteration)\n",
    "    num=100000\n",
    "    #file_iter='10w_'+str(iteration)\n",
    "    moe_val='/Users/shujiaohuang_Mac/Downloads/moe_val_'+str(file_iter)+'.tfrecord'\n",
    "    filename='both_moe_logistic_val_'+str(file_iter)+'.tfrecord'\n",
    "    writer = tf.python_io.TFRecordWriter(filename)\n",
    "    if iter<logistic_2feature_eval_stacking_new_feature.shape[0]/num:\n",
    "        logistic_feature_temp=logistic_2feature_eval_stacking_new_feature[int(iteration-1)*num:int(iteration)*num]\n",
    "    else:\n",
    "        logistic_feature_temp=logistic_2feature_eval_stacking_new_feature[int(iteration-1)*num::]\n",
    "    N_logistic=NumpyToTFHelper(logistic_feature_temp) \n",
    "    n_logistic = N_logistic.get_next()\n",
    "    for example in tf.python_io.tf_record_iterator(moe_val):\n",
    "        moe_example=tf.train.Example.FromString(example)\n",
    "        example_both_moe_logistic=tf.train.Example(\n",
    "            features=tf.train.Features(\n",
    "                feature={\n",
    "                    'video_id':moe_example.features.feature['video_id'],\n",
    "                    'labels':moe_example.features.feature['labels'],\n",
    "                    'moe_newfeature':moe_example.features.feature['New_feature'],\n",
    "                    'logistic_newfeature':_floats_feature([float(i) for i in n_logistic])\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "        writer.write(example_both_moe_logistic.SerializeToString())\n",
    "        n_logistic=N_logistic.get_next()\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84vZctjYpkY\n",
      "CdYRJB8bMpQ\n",
      "HDPqsjayHpA\n",
      "1Gj6Syodboc\n"
     ]
    }
   ],
   "source": [
    "print(logistic_2feature_eval_stacking_new_feature_withid[0][200000])\n",
    "print(logistic_2feature_eval_stacking_new_feature_withid[0][300000])\n",
    "print(logistic_2feature_eval_stacking_new_feature_withid[0][400000])\n",
    "print(logistic_2feature_eval_stacking_new_feature_withid[0][50000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.        0.999973  0.       ...,  0.        0.        0.      ]\n",
      "[ 0.        0.999711  0.021052 ...,  0.        0.        0.      ]\n",
      "[ 0.9528    0.016312  0.010455 ...,  0.        0.        0.      ]\n"
     ]
    }
   ],
   "source": [
    "print(logistic_2feature_eval_stacking_new_feature_withid[1][200000])\n",
    "print(logistic_2feature_eval_stacking_new_feature_withid[1][300000])\n",
    "print(logistic_2feature_eval_stacking_new_feature_withid[1][400000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "723156"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=logistic_2feature_eval_stacking_new_feature_withid[0].index('VzifVf2frGc')\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'VzifVf2frGc'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_2feature_eval_stacking_new_feature_withid[0][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.      ,  0.117789,  0.101857, ...,  0.      ,  0.      ,  0.      ])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_2feature_eval_stacking_new_feature_withid[1][i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logistic_2feature_test_blending_new_feature_withid=stacking_feature('/Users/shujiaohuang_Mac/Downloads/logistic_test_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logistic_2feature_test_blending_new_feature=logistic_2feature_test_blending_new_feature_withid[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.305126,  0.955644,  0.      , ...,  0.      ,  0.      ,  0.      ],\n",
       "       [ 0.16744 ,  0.04067 ,  0.012538, ...,  0.      ,  0.      ,  0.      ],\n",
       "       [ 0.      ,  0.004725,  0.      , ...,  0.      ,  0.      ,  0.      ],\n",
       "       ..., \n",
       "       [ 0.      ,  0.009766,  0.013569, ...,  0.      ,  0.      ,  0.      ],\n",
       "       [ 0.150349,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ],\n",
       "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_2feature_test_blending_new_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/shujiaohuang_Mac/Downloads/moe_test_all/moe_test_5w_1.tfrecord\n",
      "14.0128\n",
      "True\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'builtin_function_or_method' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-72ece3604bb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogistic_2feature_test_blending_new_feature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mlogistic_2feature_test_blending_new_feature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mlogistic_feature_temp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogistic_2feature_test_blending_new_feature\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogistic_feature_temp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'builtin_function_or_method' and 'int'"
     ]
    }
   ],
   "source": [
    "iteration=1\n",
    "num=50000\n",
    "moe_test='/Users/shujiaohuang_Mac/Downloads/moe_test_all/moe_test_5w_'+str(iteration)+'.tfrecord'\n",
    "print(moe_test)\n",
    "print(logistic_2feature_test_blending_new_feature.shape[0]/num)\n",
    "print(iteration<logistic_2feature_test_blending_new_feature.shape[0]/num)\n",
    "logistic_feature_temp=logistic_2feature_test_blending_new_feature[int(iteration-1)*num:int(iteration)*num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "# Both moe and logisitc test tfrecord\n",
    "for iteration in range(1,16):\n",
    "    print(iteration)\n",
    "    num=50000\n",
    "    moe_test='/Users/shujiaohuang_Mac/Downloads/moe_test_all/moe_test_5w_'+str(iteration)+'.tfrecord'\n",
    "    filename='both_moe_logistic_test_5w_'+str(iteration)+'.tfrecord'\n",
    "    writer = tf.python_io.TFRecordWriter(filename)\n",
    "    if iteration<logistic_2feature_test_blending_new_feature.shape[0]/num:\n",
    "        logistic_feature_temp=logistic_2feature_test_blending_new_feature[int(iteration-1)*num:int(iteration)*num]\n",
    "    else:\n",
    "        logistic_feature_temp=logistic_2feature_test_blending_new_feature[int(iteration-1)*num::]\n",
    "    N_logistic=NumpyToTFHelper(logistic_feature_temp) \n",
    "    n_logistic = N_logistic.get_next()\n",
    "    for example in tf.python_io.tf_record_iterator(moe_test):\n",
    "        moe_example=tf.train.Example.FromString(example)\n",
    "        example_both_moe_logistic=tf.train.Example(\n",
    "            features=tf.train.Features(\n",
    "                feature={\n",
    "                    'video_id':moe_example.features.feature['video_id'],\n",
    "                    'labels':moe_example.features.feature['labels'],\n",
    "                    'moe_newfeature':moe_example.features.feature['New_feature'],\n",
    "                    'logistic_newfeature':_floats_feature([float(i) for i in n_logistic])\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "        writer.write(example_both_moe_logistic.SerializeToString())\n",
    "        n_logistic=N_logistic.get_next()\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.305126  0.955644  0.       ...,  0.        0.        0.      ]\n",
      "[ 0.012251  0.008676  0.       ...,  0.        0.        0.      ]\n",
      "[ 0.        0.        0.984217 ...,  0.        0.        0.      ]\n",
      "[ 0.032548  0.006364  0.024194 ...,  0.        0.        0.      ]\n"
     ]
    }
   ],
   "source": [
    "print(logistic_2feature_test_blending_new_feature_withid[1][0])\n",
    "print(logistic_2feature_test_blending_new_feature_withid[1][50000])\n",
    "print(logistic_2feature_test_blending_new_feature_withid[1][100000])\n",
    "print(logistic_2feature_test_blending_new_feature_withid[1][150000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read test.tfrecord\n",
    "video_lvl_record='/Users/shujiaohuang_Mac/Downloads/test-1.tfrecord'\n",
    "for example in tf.python_io.tf_record_iterator(video_lvl_record):\n",
    "    tf_example = tf.train.Example.FromString(example)\n",
    "    break\n",
    "tf_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "file='/Users/shujiaohuang_Mac/Downloads/moe_2feature_predictions.csv'\n",
    "lines=open(file).readlines()\n",
    "result=[]\n",
    "test_id=[]\n",
    "for e,line in enumerate(lines):\n",
    "    if e>0:\n",
    "        row=line.strip().split(\",\")\n",
    "        string_list=row[1].split(\" \")\n",
    "        float_list=[float(string_list[x]) if x%2==1 else string_list[x] for x in range(0,len(string_list))]\n",
    "        newlist=[float_list[x:x+2] for x in range(0,len(float_list),2)]\n",
    "        score_dict={}\n",
    "        for x in range(0,len(newlist)):\n",
    "            score_dict[newlist[x][0]]=(newlist[x][1])\n",
    "        result.append(score_dict)\n",
    "        test_id.append(row[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700640, 4716)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature=DictVectorizer(sparse=False).fit_transform(result)\n",
    "feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, 700640)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_id),len(test_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try\n",
    "# without npz file\n",
    "iter=1\n",
    "num=3\n",
    "test_id_temp=np.array([test_id[int(iter-1)*num:int(iter)*num]])\n",
    "feature_temp=feature[int(iter-1)*num:int(iter)*num]\n",
    "#test_moe_temp=np.concatenate((test_id_temp.T,feature_temp),axis=1)\n",
    "#filename='moe_test_'+str(iter)+'_without_npz.tfrecord'\n",
    "#writer = tf.python_io.TFRecordWriter(filename)\n",
    "#N = NumpyToTFHelper(test_moe_temp) \n",
    "#n = N.get_next()\n",
    "N_feature=NumpyToTFHelper(feature_temp)\n",
    "n_feature=N_feature.get_next()\n",
    "N_id=NumpyToTFHelper(test_id_temp.T)\n",
    "n_id=N_id.get_next()\n",
    "while n is not None:\n",
    "    raw=n.tostring()\n",
    "    example = tf.train.Example(\n",
    "        features=tf.train.Features(\n",
    "            feature={\n",
    "                'video_id':_bytes_feature(bytes(n_id[0],'utf-8')),\n",
    "                'labels':_int64list_feature([]),\n",
    "                'New_feature':_floats_feature([float(i) for i in n_feature])\n",
    "            }\n",
    "        )\n",
    "    ) \n",
    "    print(example.features.feature['video_id'])\n",
    "    #writer.write(example.SerializeToString())\n",
    "    n_feature=N_feature.get_next()\n",
    "    n_id=N_id.get_next()\n",
    "#writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_id,n_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(test_id[int(iter-1)*num:int(iter)*num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.0128"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature.shape[0]/50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# without npz file\n",
    "num=50000\n",
    "for iter in range(1,16):\n",
    "    if iter<feature.shape[0]/num:\n",
    "        test_id_temp=np.array([test_id[int(iter-1)*num:int(iter)*num]])\n",
    "        feature_temp=feature[int(iter-1)*num:int(iter)*num]\n",
    "    else:\n",
    "        test_id_temp=np.array([test_id[int(iter-1)*num::]])\n",
    "        feature_temp=feature[int(iter-1)*num::]\n",
    "    filename='moe_test_5w_'+str(iter)+'.tfrecord'\n",
    "    writer = tf.python_io.TFRecordWriter(filename)\n",
    "    N_feature = NumpyToTFHelper(feature_temp) \n",
    "    n_feature = N_feature.get_next()\n",
    "    N_id=NumpyToTFHelper(test_id_temp.T) \n",
    "    n_id = N_id.get_next()\n",
    "    while n_id is not None:\n",
    "        raw=n.tostring()\n",
    "        example = tf.train.Example(\n",
    "            features=tf.train.Features(\n",
    "                feature={\n",
    "                    'video_id':_bytes_feature(bytes(n_id[0],'utf-8')),\n",
    "                    'labels':_int64list_feature([]),\n",
    "                    'New_feature':_floats_feature([float(i) for i in n_feature])\n",
    "                }\n",
    "            )\n",
    "        ) \n",
    "        writer.write(example.SerializeToString())\n",
    "        n_feature=N_feature.get_next()\n",
    "        n_id=N_id.get_next()\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "moe_test_temp1='moe_test_2.tfrecord'\n",
    "for example in tf.python_io.tf_record_iterator(moe_test_temp1):\n",
    "    tf_example = tf.train.Example.FromString(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytes_list {\n",
       "  value: \"100646753\"\n",
       "}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_example.features.feature['video_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19999"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_id.index('100646753')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(X_train),type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fit_log=linear_model.LogisticRegression(C=1e5).fit(X_train[0:10000],y_train[0][0:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blending_logistic_10000=MultiOutputClassifier(linear_model.LogisticRegression(C=1e5)).fit(X_train[0:10000], y_train[0:10000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phat_logistic=blending_logistic.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hat={}\n",
    "for i in range(len(phat)):\n",
    "    b={j:phat[i][j] for j in range(len(phat[i]))}\n",
    "    b_sort=sorted(b.items(),key=lambda x:x[1],reverse=True)\n",
    "    a=b_sort[range(20)]\n",
    "    c=''\n",
    "    for j in a:\n",
    "        temp=\" \".join(map(str,j))\n",
    "        c=c+temp+' '\n",
    "    hat['id'+str(i)]=c\n",
    "final_stacking=pd.DataFrame(pd.Series(hat),index=hat.keys(),columns=['LabelConfidencePair'])\n",
    "final_stacking.index.name='VideoId'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_stacking.to_csv('stacking_logistic.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
